{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure python version <= 3.8.x\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q stable-baselines3[extra]\n",
    "!pip install -q pyglet==1.3.2\n",
    "# !choco install swig  # MUST install swig. User apt install for linux based kernel\n",
    "!pip install gym[atari,box2d]==0.17.3\n",
    "# !pip install ale-py\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym \n",
    "from stable_baselines3 import PPO, A2C\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_env(env, model, episodes=5, render=False):\n",
    "    for episode in range(1, episodes+1):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        score = 0 \n",
    "        while not done:\n",
    "            action, _state = (env.action_space.sample(), None) if model is None else model.predict(obs)\n",
    "            obs, reward, done, _info = env.step(action)\n",
    "            score+=reward\n",
    "            if render:\n",
    "                env.render()\n",
    "        print('Episode:{} Score:{}'.format(episode, score))\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CartPole\n",
    "ref: [link](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(2)\n",
      "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "print(env.action_space)  # 2 acts - left, right\n",
    "print(env.observation_space)  # 4 obs - cart position, cart valocity, pole angle, pole angular velocity\n",
    "# reward max = episode termination = 200 obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:35.0\n",
      "Episode:2 Score:18.0\n",
      "Episode:3 Score:11.0\n",
      "Episode:4 Score:13.0\n",
      "Episode:5 Score:24.0\n"
     ]
    }
   ],
   "source": [
    "run_env(env, None, episodes=5, render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "env = DummyVecEnv([lambda: env])\n",
    "log_path = os.path.join('logs', \"cartpole\")\n",
    "model = PPO('MlpPolicy', env, verbose = True, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('pretrained_weights', 'cartpole')\n",
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=200, verbose=1)\n",
    "eval_callback = EvalCallback(env, \n",
    "                             callback_on_new_best=stop_callback, \n",
    "                             eval_freq=10000, \n",
    "                             best_model_save_path=save_path, \n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to logs\\PPO_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1000, episode_reward=193.40 +/- 8.14\n",
      "Episode length: 193.40 +/- 8.14\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 193      |\n",
      "|    mean_reward     | 193      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1000     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=2000, episode_reward=169.80 +/- 17.52\n",
      "Episode length: 169.80 +/- 17.52\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 170      |\n",
      "|    mean_reward     | 170      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 2000     |\n",
      "---------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 273  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 7    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "Eval num_timesteps=3000, episode_reward=146.20 +/- 44.76\n",
      "Episode length: 146.20 +/- 44.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 146         |\n",
      "|    mean_reward          | 146         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009511966 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | -0.00105    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.79        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 54.5        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4000, episode_reward=195.60 +/- 8.80\n",
      "Episode length: 195.60 +/- 8.80\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 196      |\n",
      "|    mean_reward     | 196      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 4000     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 399  |\n",
      "|    iterations      | 2    |\n",
      "|    time_elapsed    | 10   |\n",
      "|    total_timesteps | 4096 |\n",
      "-----------------------------\n",
      "Eval num_timesteps=5000, episode_reward=164.00 +/- 44.38\n",
      "Episode length: 164.00 +/- 44.38\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 164        |\n",
      "|    mean_reward          | 164        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 5000       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01100708 |\n",
      "|    clip_fraction        | 0.0793     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.667     |\n",
      "|    explained_variance   | 0.0875     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 10.9       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0192    |\n",
      "|    value_loss           | 31.6       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=118.60 +/- 42.03\n",
      "Episode length: 118.60 +/- 42.03\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 119      |\n",
      "|    mean_reward     | 119      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 6000     |\n",
      "---------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 451  |\n",
      "|    iterations      | 3    |\n",
      "|    time_elapsed    | 13   |\n",
      "|    total_timesteps | 6144 |\n",
      "-----------------------------\n",
      "Eval num_timesteps=7000, episode_reward=159.60 +/- 49.50\n",
      "Episode length: 159.60 +/- 49.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 160         |\n",
      "|    mean_reward          | 160         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 7000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010005692 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.632      |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=162.40 +/- 46.16\n",
      "Episode length: 162.40 +/- 46.16\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 162      |\n",
      "|    mean_reward     | 162      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 8000     |\n",
      "---------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 499  |\n",
      "|    iterations      | 4    |\n",
      "|    time_elapsed    | 16   |\n",
      "|    total_timesteps | 8192 |\n",
      "-----------------------------\n",
      "Eval num_timesteps=9000, episode_reward=200.00 +/- 0.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 200         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 9000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008665586 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.606      |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    value_loss           | 50.6        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "Stopping training because the mean reward 200.00  is above the threshold 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x14e684be610>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to logs\\PPO_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1114 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 971         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011044263 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.685      |\n",
      "|    explained_variance   | 0.000885    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.79        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 950         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011727839 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.661      |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 32.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 962         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007901549 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.632      |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 53.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 977         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005345235 |\n",
      "|    clip_fraction        | 0.0539      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.614      |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 62.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 968         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011149552 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.59       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    value_loss           | 57.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 960        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01045225 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.59      |\n",
      "|    explained_variance   | 0.687      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 15.2       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    value_loss           | 45.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 944         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012037078 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.595      |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 943          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061253514 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.578       |\n",
      "|    explained_variance   | 0.436        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 27.8         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00687     |\n",
      "|    value_loss           | 86.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 946          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023701664 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.566       |\n",
      "|    explained_variance   | 0.363        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 37.6         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    value_loss           | 98           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1e5ff908610>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export & import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = os.path.join('pretrained_weights', 'cartpole', 'cartpole_ppo_20k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "model = PPO.load(checkpoint, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=1, render=True, warn=False, return_episode_rewards=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:[200.]\n",
      "Episode:2 Score:[200.]\n"
     ]
    }
   ],
   "source": [
    "run_env(env, model, episodes=2, render=True)\n",
    "# GOOD JOB!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log_path = os.path.join(log_path, 'PPO_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python -m tensorboard.main --logdir={training_log_path}  --port 6006\n",
    "# http://localhost:6006/\n",
    "\n",
    "# avg reward, episode length, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breakout\n",
    "\n",
    "link: [ref](https://gym.openai.com/envs/Breakout-v0/); [rom](http://www.atarimania.com/roms/Roms.rar)\n",
    "\n",
    "extract `ROMS` and `HC ROMS` in `Roms.rar`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m atari_py.import_roms .\\rom\\ROMS\n",
    "# if has error in win10, follow https://github.com/openai/gym/issues/1726#issuecomment-550580367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(4)\n",
      "Box(0, 255, (210, 160, 3), uint8)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Breakout-v0\")\n",
    "print(env.action_space)  # 4 acts\n",
    "print(env.observation_space)  # min val, max val, (heightm, width, 3 channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:1.0\n",
      "Episode:2 Score:2.0\n",
      "Episode:3 Score:1.0\n",
      "Episode:4 Score:1.0\n",
      "Episode:5 Score:4.0\n"
     ]
    }
   ],
   "source": [
    "run_env(env, None, episodes=5, render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "env = make_atari_env('Breakout-v0', n_envs=4, seed=0)\n",
    "env = VecFrameStack(env, n_stack=4)\n",
    "log_path = os.path.join(\"logs\", \"breakout\")\n",
    "model = A2C(\"CnnPolicy\", env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to logs\\breakout\\A2C_1\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 281      |\n",
      "|    ep_rew_mean        | 1.56     |\n",
      "| time/                 |          |\n",
      "|    fps                | 56       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.34    |\n",
      "|    explained_variance | 0.0706   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.0549   |\n",
      "|    value_loss         | 0.162    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 281      |\n",
      "|    ep_rew_mean        | 1.53     |\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.35    |\n",
      "|    explained_variance | 0.295    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.0363  |\n",
      "|    value_loss         | 0.0421   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 285      |\n",
      "|    ep_rew_mean        | 1.64     |\n",
      "| time/                 |          |\n",
      "|    fps                | 59       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.09    |\n",
      "|    explained_variance | 0.848    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -0.286   |\n",
      "|    value_loss         | 0.142    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 292      |\n",
      "|    ep_rew_mean        | 1.82     |\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.21    |\n",
      "|    explained_variance | 0.972    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.0649  |\n",
      "|    value_loss         | 0.0147   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 307      |\n",
      "|    ep_rew_mean        | 2.13     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.915   |\n",
      "|    explained_variance | 0.808    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -0.0457  |\n",
      "|    value_loss         | 0.162    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x1893eea1a00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=2000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export & import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = os.path.join('pretrained_weights', 'breakout', 'breakout_a2c_10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:276: UserWarning: Path 'pretrained_weights\\breakout' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "model.save(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "model = A2C.load(checkpoint, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=3, render=True, warn=False, return_episode_rewards=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_atari_env('Breakout-v0', n_envs=1, seed=0)\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:166: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "checkpoint = os.path.join('pretrained_weights', 'breakout', 'breakout_a2c_2m')\n",
    "model = A2C.load(checkpoint, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:[0.]\n",
      "Episode:2 Score:[0.]\n",
      "Episode:3 Score:[7.]\n",
      "Episode:4 Score:[0.]\n",
      "Episode:5 Score:[4.]\n"
     ]
    }
   ],
   "source": [
    "run_env(env, model, episodes=5, render=True)\n",
    "# GOOD JOB!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CarRacing\n",
    "link: [ref](https://gym.openai.com/envs/CarRacing-v0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(-1.0, 1.0, (3,), float32)\n",
      "Box(0, 255, (96, 96, 3), uint8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CarRacing-v0\")\n",
    "print(env.action_space)  # 3 acts between -1 to 1\n",
    "print(env.observation_space)  # min val, max val, (heightm, width, 3 channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1188..1489 -> 301-tiles track\n",
      "Episode:1 Score:-33.33333333333387\n"
     ]
    }
   ],
   "source": [
    "run_env(env, None, episodes=1, render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CarRacing-v0\")\n",
    "env = DummyVecEnv([lambda: env])\n",
    "log_path = os.path.join('logs', 'carracing')\n",
    "model = PPO(\"CnnPolicy\", env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1067..1338 -> 271-tiles track\n",
      "Logging to logs\\carracing\\PPO_1\n",
      "Track generation: 1292..1619 -> 327-tiles track\n",
      "Track generation: 1139..1428 -> 289-tiles track\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 90   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 22   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "Track generation: 1163..1458 -> 295-tiles track\n",
      "Track generation: 988..1239 -> 251-tiles track\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008518707 |\n",
      "|    clip_fraction        | 0.0797      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.22       |\n",
      "|    explained_variance   | -0.00457    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00902    |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 0.553       |\n",
      "-----------------------------------------\n",
      "Track generation: 1148..1438 -> 290-tiles track\n",
      "Track generation: 997..1253 -> 256-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1104..1384 -> 280-tiles track\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011623832 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.0626      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0564      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 0.979       |\n",
      "|    value_loss           | 0.475       |\n",
      "-----------------------------------------\n",
      "Track generation: 1107..1392 -> 285-tiles track\n",
      "Track generation: 1160..1454 -> 294-tiles track\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 162        |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01126997 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.18      |\n",
      "|    explained_variance   | 0.091      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0901     |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0154    |\n",
      "|    std                  | 0.972      |\n",
      "|    value_loss           | 0.473      |\n",
      "----------------------------------------\n",
      "Track generation: 1059..1328 -> 269-tiles track\n",
      "Track generation: 1208..1514 -> 306-tiles track\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012518989 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0372      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 0.955       |\n",
      "|    value_loss           | 0.475       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x24b7f04fc10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export & import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = os.path.join('pretrained_weights', 'carracing', 'carracing_ppo_10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:276: UserWarning: Path 'pretrained_weights\\carracing' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "model.save(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "model = A2C.load(checkpoint, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1169..1465 -> 296-tiles track\n",
      "Track generation: 1183..1483 -> 300-tiles track\n"
     ]
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=1, render=True, warn=False, return_episode_rewards=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:166: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:166: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = os.path.join('pretrained_weights', 'carracing', 'carracing_ppo_2m')\n",
    "model = A2C.load(checkpoint, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1285..1610 -> 325-tiles track\n",
      "Track generation: 1155..1448 -> 293-tiles track\n",
      "Episode:1 Score:[736.426]\n",
      "Track generation: 1063..1333 -> 270-tiles track\n",
      "Track generation: 1126..1416 -> 290-tiles track\n",
      "Episode:2 Score:[821.9406]\n",
      "Track generation: 1117..1400 -> 283-tiles track\n",
      "Track generation: 1251..1568 -> 317-tiles track\n",
      "Episode:3 Score:[811.3566]\n"
     ]
    }
   ],
   "source": [
    "run_env(env, model, episodes=3, render=True)\n",
    "# GOOD JOB!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom - GuessNum\n",
    "ans is 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete \n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(3)\n",
      "[[0.05858376 0.7883015  0.8729452 ]\n",
      " [0.9673796  0.35261858 0.72823906]\n",
      " [0.9608749  0.43137282 0.29857707]]\n",
      "[[ 31 172 216]\n",
      " [ 82  86  13]\n",
      " [164 142 229]]\n",
      "(1, array([56.542503], dtype=float32))\n",
      "OrderedDict([('height', 0), ('speed', array([61.57991], dtype=float32))])\n",
      "[0 1 1 0]\n",
      "[1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(Discrete(3))\n",
    "print(Box(0,1,shape=(3,3)).sample())\n",
    "print(Box(0,255,shape=(3,3), dtype=int).sample())\n",
    "print(Tuple((Discrete(2), Box(0,100, shape=(1,)))).sample())\n",
    "print(Dict({'height':Discrete(2), \"speed\":Box(0,100, shape=(1,))}).sample())\n",
    "print(MultiBinary(4).sample())\n",
    "print(MultiDiscrete([5,2,2]).sample())  # 0 to X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuessNumEnv(Env):  \n",
    "    def __init__(self):\n",
    "        self._ans = 42\n",
    "        self._init_state = np.array(self._ans+10 + random.randint(-5,5))\n",
    "        self._thresh = 3\n",
    "\n",
    "        self.action_space = Discrete(3)  # decrease, stay, increase\n",
    "        self.observation_space = Box(0, 100, shape=(1, ), dtype=int)\n",
    "        self.state = self._init_state\n",
    "        self.guess_length = 60\n",
    "       \n",
    "    def step(self, action):\n",
    "        self.state += (action -1) * 3  # apply action to state\n",
    "        self.guess_length -= 1  # track length\n",
    "        \n",
    "        # Calculate reward\n",
    "        if self.state >=self._ans-self._thresh and self.state <=self._ans+self._thresh: \n",
    "            reward =1 \n",
    "        else: \n",
    "            reward = -1 \n",
    "        \n",
    "        # Check if guess is done\n",
    "        done = True if self.guess_length <= 0 else False\n",
    "        \n",
    "        # Apply noise\n",
    "        self.state += random.randint(-1,1)\n",
    "\n",
    "        # placeholder for info\n",
    "        info = {}\n",
    "        \n",
    "        # Return step information\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        # placeholder for visualization\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        # Reset guess number \n",
    "        self.state = np.array([self._init_state])\n",
    "        # Reset guess time\n",
    "        self.guess_length = 60 \n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51]\n"
     ]
    }
   ],
   "source": [
    "env=GuessNumEnv()\n",
    "check_env(env, warn=True)\n",
    "print(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-60\n",
      "Episode:2 Score:-56\n",
      "Episode:3 Score:-60\n",
      "Episode:4 Score:-54\n",
      "Episode:5 Score:-48\n"
     ]
    }
   ],
   "source": [
    "run_env(env, None, episodes=5, render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('logs', 'guessnum')\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('pretrained_weights', 'guessnum')\n",
    "# stop_callback = StopTrainingOnRewardThreshold(reward_threshold=50, verbose=1)\n",
    "eval_callback = EvalCallback(env, \n",
    "                             callback_on_new_best=None, \n",
    "                             eval_freq=10000, \n",
    "                             best_model_save_path=save_path, \n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to logs\\guessnum\\PPO_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60       |\n",
      "|    ep_rew_mean     | -43.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -41.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 470          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0136798145 |\n",
      "|    clip_fraction        | 0.187        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.00174     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0139      |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -41.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 557         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010455061 |\n",
      "|    clip_fraction        | 0.0435      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.0138      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    value_loss           | 46.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -38.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 594          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053602597 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.0953       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    value_loss           | 46.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -39.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 646          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055366354 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.0663       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 33.8         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.000654    |\n",
      "|    value_loss           | 53.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -37.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 682         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009131804 |\n",
      "|    clip_fraction        | 0.0282      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    value_loss           | 54.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -39.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 710         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009926219 |\n",
      "|    clip_fraction        | 0.00767     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.0385      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | 0.00022     |\n",
      "|    value_loss           | 59.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -39.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 737          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012375615 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.178        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 25.5         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.000374    |\n",
      "|    value_loss           | 46           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -43.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 761         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012651013 |\n",
      "|    clip_fraction        | 0.0373      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    value_loss           | 44.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -46.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 771         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014339699 |\n",
      "|    clip_fraction        | 0.0513      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.994      |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -49.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 788          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035201847 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.968       |\n",
      "|    explained_variance   | 0.647        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.52         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    value_loss           | 23.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -50.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 801          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035192627 |\n",
      "|    clip_fraction        | 0.0401       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.926       |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    value_loss           | 28.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -52         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 812         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009573158 |\n",
      "|    clip_fraction        | 0.0441      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.942      |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -53         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 822         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008336179 |\n",
      "|    clip_fraction        | 0.0232      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.916      |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -53.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 833         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007247676 |\n",
      "|    clip_fraction        | 0.0585      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.897      |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -54.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 840         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007310222 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.843      |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -54.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 842         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012154013 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.806      |\n",
      "|    explained_variance   | 0.659       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -54.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 852          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051577957 |\n",
      "|    clip_fraction        | 0.039        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.806       |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    value_loss           | 43.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -54.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 859         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006587011 |\n",
      "|    clip_fraction        | 0.0539      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.758      |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00124    |\n",
      "|    value_loss           | 39.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -54.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 863         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005734767 |\n",
      "|    clip_fraction        | 0.0437      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.749      |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00428    |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -54.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 868         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003585285 |\n",
      "|    clip_fraction        | 0.0377      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.727      |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0022     |\n",
      "|    value_loss           | 40          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -54.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 874          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050124163 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.732       |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    value_loss           | 37.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -54.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 877         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003270755 |\n",
      "|    clip_fraction        | 0.0408      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.708      |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -55.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 877         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007804758 |\n",
      "|    clip_fraction        | 0.0385      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.702      |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00148    |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -55.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 883         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004596625 |\n",
      "|    clip_fraction        | 0.0621      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.684      |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -55.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 887          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055920808 |\n",
      "|    clip_fraction        | 0.0685       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.693       |\n",
      "|    explained_variance   | 0.753        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    value_loss           | 28.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -55.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 888          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076030027 |\n",
      "|    clip_fraction        | 0.0682       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.67        |\n",
      "|    explained_variance   | 0.777        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.36         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -55.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 893          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 64           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035203518 |\n",
      "|    clip_fraction        | 0.0826       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.653       |\n",
      "|    explained_variance   | 0.8          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.55         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    value_loss           | 22.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -55.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 896          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049785236 |\n",
      "|    clip_fraction        | 0.0892       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.635       |\n",
      "|    explained_variance   | 0.826        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.69         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    value_loss           | 21.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -55.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 896         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018838806 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.596      |\n",
      "|    explained_variance   | 0.826       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.29        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00478    |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -55.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 896          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056945956 |\n",
      "|    clip_fraction        | 0.0945       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.593       |\n",
      "|    explained_variance   | 0.844        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.29         |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.000571    |\n",
      "|    value_loss           | 19.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -55.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 898          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040030424 |\n",
      "|    clip_fraction        | 0.0891       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.884        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.78         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    value_loss           | 14.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -55.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 900         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011966087 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.542      |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.71        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00908    |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -55.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 902         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014245734 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.542      |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.22        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 9.73        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -55.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 906         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008189287 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.519      |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.96        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00489    |\n",
      "|    value_loss           | 9.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -55.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 908         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014727274 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.497      |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.12        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    value_loss           | 9.76        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -55.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 905         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012322437 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.503      |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.35        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    value_loss           | 5.45        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | -55.2      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 909        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 85         |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00832987 |\n",
      "|    clip_fraction        | 0.0946     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.479     |\n",
      "|    explained_variance   | 0.937      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.32       |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.00162   |\n",
      "|    value_loss           | 4.86       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -55.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 912          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034991005 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.436       |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.86         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | 0.000443     |\n",
      "|    value_loss           | 4.46         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -55.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 910          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070351567 |\n",
      "|    clip_fraction        | 0.0699       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.413       |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.13         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    value_loss           | 3.86         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -55.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 911          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073193754 |\n",
      "|    clip_fraction        | 0.0875       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.392       |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    value_loss           | 3.49         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -55         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 913         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032806307 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.367      |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.78        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | 0.00819     |\n",
      "|    value_loss           | 3.56        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -55          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 911          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 96           |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038332816 |\n",
      "|    clip_fraction        | 0.048        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.294       |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.09         |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.000169    |\n",
      "|    value_loss           | 2.2          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -55         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 910         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006540269 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | 0.00647     |\n",
      "|    value_loss           | 2.63        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 60        |\n",
      "|    ep_rew_mean          | -55.2     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 911       |\n",
      "|    iterations           | 45        |\n",
      "|    time_elapsed         | 101       |\n",
      "|    total_timesteps      | 92160     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0111885 |\n",
      "|    clip_fraction        | 0.0581    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.288    |\n",
      "|    explained_variance   | 0.982     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.917     |\n",
      "|    n_updates            | 440       |\n",
      "|    policy_gradient_loss | 0.00184   |\n",
      "|    value_loss           | 2.19      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -54.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 910         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009842501 |\n",
      "|    clip_fraction        | 0.0769      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.223      |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.978       |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    value_loss           | 1.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -54.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 909         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005289062 |\n",
      "|    clip_fraction        | 0.0557      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.000866   |\n",
      "|    value_loss           | 2.4         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -54.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 912         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021553962 |\n",
      "|    clip_fraction        | 0.0432      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.229      |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | 0.00308     |\n",
      "|    value_loss           | 2.2         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -54.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 911          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063116634 |\n",
      "|    clip_fraction        | 0.0339       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.16        |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.649        |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | 0.00211      |\n",
      "|    value_loss           | 1.09         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x25d4cddda00>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000) # , callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export & import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = os.path.join('pretrained_weights', 'guessnum', 'guessnum_ppo_100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "model = PPO.load(checkpoint, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=1, render=False, warn=False, return_episode_rewards=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = os.path.join('pretrained_weights', 'guessnum', 'best_model')\n",
    "model = PPO.load(checkpoint, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-16\n",
      "Episode:2 Score:20\n",
      "Episode:3 Score:-6\n"
     ]
    }
   ],
   "source": [
    "run_env(env, model, episodes=3, render=True)\n",
    "# Mehhh not so good at guessing... very inconsistent too."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aecd030d4c8316a52bf122072e28f84bcc79844c2684e041fef2e3f1d9f59078"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
